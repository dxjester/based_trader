{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BASED COINBASE BOT TRADER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FILENAME: model_trader.ipynb\n",
    "    \n",
    "DATE UPDATE: 6-MAR-21\n",
    "    \n",
    "VERSION: 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PHASE 1: Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import getpass\n",
    "import json as js\n",
    "from datetime import datetime, timedelta\n",
    "# IMPORTS\n",
    "from coinbase.wallet.client import Client\n",
    "from coinbase.wallet.model import APIObject\n",
    "\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "\n",
    "import requests\n",
    "from requests.exceptions import HTTPError\n",
    "\n",
    "\n",
    "# machine learning libraries\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Uncomment this if you like to use the old MPL library\n",
    "#from mpl_finance import candlestick_ohlc\n",
    "\n",
    "import mplfinance as mpf\n",
    "import matplotlib.dates as mpl_dates\n",
    "import matplotlib.ticker as tkr\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "\n",
    "import cbpro\n",
    "import json, hmac, hashlib, time, requests\n",
    "from requests.auth import AuthBase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FUNCTION DECLARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect(url, *args, **kwargs):\n",
    "    try:\n",
    "        if kwargs.get('param', None) is not None:\n",
    "            response = requests.get(url,params)\n",
    "        else:\n",
    "            response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        #print('HTTP connection success!')\n",
    "        return response\n",
    "    except HTTPError as http_err:\n",
    "        print(f'HTTP error occurred: {http_err}')\n",
    "    except Exception as err:\n",
    "        print(f'Other error occurred: {err}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_ma_pos(val):\n",
    "    \n",
    "    if val > 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_ewma_vectorized(data, window):\n",
    "\n",
    "    alpha = 2 /(window + 1.0)\n",
    "    alpha_rev = 1-alpha\n",
    "\n",
    "    scale = 1/alpha_rev\n",
    "    n = data.shape[0]\n",
    "\n",
    "    r = np.arange(n)\n",
    "    scale_arr = scale**r\n",
    "    offset = data[0]*alpha_rev**(r+1)\n",
    "    pw0 = alpha*alpha_rev**(n-1)\n",
    "\n",
    "    mult = data*pw0*scale_arr\n",
    "    cumsums = mult.cumsum()\n",
    "    out = offset + cumsums*scale_arr[::-1]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before implementation, set environmental variables with the names API_KEY and API_SECRET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "API_KEY = getpass.getpass(prompt='Please enter the API Key: ', stream=None)\n",
    "API_SECRET = getpass.getpass(prompt='Please enter the API Secret: ', stream=None)\n",
    "passphrase = getpass.getpass(prompt='Please enter the API passphrase: ', stream=None)\n",
    "\n",
    "import cbpro\n",
    "auth_client = cbpro.AuthenticatedClient(API_KEY, API_SECRET, passphrase)\n",
    "\n",
    "# Use the sandbox API (requires a different set of API access credentials)\n",
    "#auth_client = cbpro.AuthenticatedClient(API_KEY, API_SECRET, passphrase, api_url=\"https://api-public.sandbox.pro.coinbase.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish Coinbase API connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to the Coinbase Pro API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REST_API = 'https://api.pro.coinbase.com'\n",
    "PRODUCTS = REST_API+'/products'\n",
    "\n",
    "response = connect(PRODUCTS)\n",
    "response_content = response.content\n",
    "response_text = response.text\n",
    "response_headers = response.headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the response headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am only interested in a few currencies that I want to trade, so let's add them here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorand Test Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MY_CURRENCIES = ['ALGO-USD']\n",
    "\n",
    "df_currencies = pd.read_json (response_text)\n",
    "\n",
    "print(\"\\nNumber of columns in the dataframe: %i\" % (df_currencies.shape[1]))\n",
    "print(\"Number of rows in the dataframe: %i\\n\" % (df_currencies.shape[0]))\n",
    "\n",
    "df_currencies['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print list of column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_currencies.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(df_currencies.columns)\n",
    "print(columns)\n",
    "print() \n",
    "df_currencies[df_currencies.id.isin(MY_CURRENCIES)][['id', 'quote_currency', 'base_min_size', 'base_max_size']].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the currency info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currency_rows = []\n",
    "for currency in MY_CURRENCIES:\n",
    "    response = connect(PRODUCTS+'/'+currency+'/stats')\n",
    "    response_content = response.content\n",
    "    data = js.loads(response_content.decode('utf-8'))\n",
    "    currency_rows.append(data)\n",
    "    \n",
    "# Create dataframe and set row index as currency name\n",
    "df_statistics = pd.DataFrame(currency_rows, index = MY_CURRENCIES)\n",
    "df_statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the last 300 days worth of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = (datetime.today() - timedelta(days=300)).isoformat()\n",
    "end_date = datetime.now().isoformat()\n",
    "\n",
    "# Please refer to the coinbase documentation on the expected parameters\n",
    "params = {'start':start_date, 'end':end_date, 'granularity':'86400'}\n",
    "response = connect(PRODUCTS+'/ALGO-USD/candles', param = params)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_text = response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add column names in line with the Coinbase Pro documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_history = pd.read_json(response_text)\n",
    "\n",
    "\n",
    "df_history.columns = ['time','low','high','open','close','volume']\n",
    "df_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will add a few more columns just for better readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_history['date'] = pd.to_datetime(df_history['time'], unit='s')\n",
    "df_history['year'] = pd.DatetimeIndex(df_history['date']).year\n",
    "df_history['month'] = pd.DatetimeIndex(df_history['date']).month\n",
    "df_history['day'] = pd.DatetimeIndex(df_history['date']).day\n",
    "df_history['hour'] = pd.DatetimeIndex(df_history['date']).hour.astype(str)\n",
    "# Only display the first 5 rows\n",
    "df_history.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_history.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_close_values = df_history['close'].tolist()\n",
    "algo_close_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorand Smoothing Average Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append new columns to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_INVESTMENT = 100 # initial investment\n",
    "algo_NO_OF_RECORDS = 0 # number of transactions\n",
    "algo_ATH = algo_close_values[0]\n",
    "algo_ATL = algo_close_values[0]\n",
    "algo_MEDIAN = 0\n",
    "algo_AVERAGE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_aggregated_list = []\n",
    "algo_aggregate_df = pd.DataFrame(columns=['Close','ATH','ATL','Median','Mean'])\n",
    "\n",
    "for value in algo_close_values:\n",
    "        \n",
    "    algo_aggregated_list.append(value)\n",
    "    \n",
    "    algo_no_of_items = len(algo_aggregated_list)\n",
    "    \n",
    "    if value > algo_ATH:\n",
    "        algo_ATH = value\n",
    "    elif value < algo_ATL:\n",
    "        algo_ATL = value\n",
    "    \n",
    "    algo_median_val = statistics.median(algo_aggregated_list)\n",
    "    algo_avg_val = statistics.mean(algo_aggregated_list)\n",
    "    print('At index number: {}'.format(algo_no_of_items))\n",
    "    \n",
    "    print(\"ATH: {}, ATL: {}, Running Median: {}, Running Mean: {}\\n\".format(algo_ATH,algo_ATL,algo_median_val,algo_avg_val))\n",
    "    \n",
    "    algo_aggregate_df.loc[algo_no_of_items] = [value, algo_ATH ,algo_ATL, algo_median_val, algo_avg_val]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add smoothing moving averages of 7 and 30 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_aggregate_df['SMA7'] = algo_aggregate_df['Close'].rolling(window=7).mean()\n",
    "algo_aggregate_df['SMA30'] = algo_aggregate_df['Close'].rolling(window=30).mean()\n",
    "\n",
    "algo_aggregate_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the SMA7 and SMA30 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(algo_aggregate_df, x=algo_aggregate_df.index, y=['Close','SMA7','SMA30'])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the difference from the SMA30 and SMA7 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_aggregate_df['diff_SMA7_SMA30'] = algo_aggregate_df['SMA7'] - algo_aggregate_df['SMA30']\n",
    "algo_aggregate_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new boolean column to determine whether the SMA30-SMA7 value is positive or negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_aggregate_df['bool_diff_SMA7_SMA30'] = algo_aggregate_df['diff_SMA7_SMA30'].apply(is_ma_pos)\n",
    "algo_aggregate_df[75:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the MACD values for each record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_aggregate_df['S-MACD'] = algo_aggregate_df['SMA7']/algo_aggregate_df['SMA30']\n",
    "fig = px.line(algo_aggregate_df, x=algo_aggregate_df.index, y=['S-MACD'])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the subplot graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Create figure with secondary y-axis\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "# Add traces\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=algo_aggregate_df.index, y=algo_aggregate_df['Close'], name=\"yaxis data\"),\n",
    "    secondary_y=False,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=algo_aggregate_df.index, y=algo_aggregate_df['S-MACD'], name=\"yaxis2 data\"),\n",
    "    secondary_y=True,\n",
    ")\n",
    "\n",
    "# Add figure title\n",
    "fig.update_layout(\n",
    "    title_text=\"Double Y Axis Example\"\n",
    ")\n",
    "\n",
    "# Set x-axis title\n",
    "fig.update_xaxes(title_text=\"xaxis title\")\n",
    "\n",
    "# Set y-axes titles\n",
    "fig.update_yaxes(title_text=\"<b>primary</b> yaxis title\", secondary_y=False)\n",
    "fig.update_yaxes(title_text=\"<b>secondary</b> yaxis title\", secondary_y=True)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot candlestick chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the original dataframe\n",
    "df_ohlc = df_history\n",
    "# Remove unnecessary columns and only show the last 30 days\n",
    "df_ohlc = df_ohlc.drop(['time','year','month','day'], axis = 1).head(30)\n",
    "# Columns must be in a specific order for the candlestick chart (OHLC)\n",
    "df_ohlc = df_ohlc[['date', 'open', 'high', 'low', 'close','volume']]\n",
    "# Index must be set as the date\n",
    "df_ohlc.set_index('date', inplace=True)\n",
    "# Inverse order is expected so let's reverse the rows in the dataframe\n",
    "df_ohlc = df_ohlc[::-1]\n",
    "mpf.plot(df_ohlc,type='candle',mav=(3,6,9),volume=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential Moving Average Test Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_aggregate_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_array = algo_aggregate_df['Close'].to_numpy()\n",
    "close_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMA10 = numpy_ewma_vectorized(close_array,10)\n",
    "EMA10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PHASE 3: Class Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df_currencies['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class token:\n",
    "    \n",
    "    def __init__(self, name, num_of_days):\n",
    "        \n",
    "        print(\"Creating {} object ...\".format(name))\n",
    "        self.REST_API = 'https://api.pro.coinbase.com'\n",
    "        self.PRODUCTS = REST_API+'/products'\n",
    "        \n",
    "        self.token_name = name\n",
    "        self.token_url = '/'+name+'/candles'\n",
    "        \n",
    "        self.start_date = (datetime.today() - timedelta(days=300)).isoformat()\n",
    "        self.end_date = datetime.now().isoformat()\n",
    "        \n",
    "        # Please refer to the coinbase documentation on the expected parameters\n",
    "        self.params = {'start':self.start_date, 'end':self.end_date, 'granularity':'86400'}\n",
    "        self.response = connect(PRODUCTS+ self.token_url, param = params)\n",
    "        \n",
    "        self.response_text = self.response.text\n",
    "        \n",
    "        self.raw_df = pd.read_json(self.response_text)\n",
    "        \n",
    "        self.raw_df.columns = ['time','low','high','open','close','volume']\n",
    "        self.raw_df['date'] = pd.to_datetime(self.raw_df['time'], unit='s')\n",
    "        self.raw_df['year'] = pd.DatetimeIndex(self.raw_df['date']).year\n",
    "        self.raw_df['month'] = pd.DatetimeIndex(self.raw_df['date']).month\n",
    "        self.raw_df['day'] = pd.DatetimeIndex(self.raw_df['date']).day\n",
    "        self.raw_df['hour'] = pd.DatetimeIndex(self.raw_df['date']).hour.astype(str)\n",
    "        self.raw_df['name'] = self.token_name\n",
    "        #self.raw_df.set_index('date', inplace=True)\n",
    "        \n",
    "        self.sma_signal = 7\n",
    "        self.sma_ma = 25\n",
    "        self.ema_signal = 12\n",
    "        self.ema_ma = 26\n",
    "        self.sma_model_accuracy = 0\n",
    "        self.ema_model_accuracy = 0\n",
    "        \n",
    "    def return_df(self):\n",
    "        \n",
    "        return self.aggregate_df\n",
    "    \n",
    "\n",
    "    def calc_sma(self):\n",
    "        \n",
    "        close_values = self.raw_df['close'][::-1].tolist()\n",
    "    \n",
    "        \n",
    "        INVESTMENT = 100 # initial investment\n",
    "        NO_OF_RECORDS = 0 # number of transactions\n",
    "        ATH = algo_close_values[0]\n",
    "        ATL = algo_close_values[0]\n",
    "        MEDIAN = 0\n",
    "        AVERAGE = 0\n",
    "        \n",
    "        aggregated_list = []\n",
    "        self.aggregate_df = pd.DataFrame(columns=['Close','ATH','ATL','Median','Mean'])\n",
    "        \n",
    "        for value in close_values:\n",
    "\n",
    "            aggregated_list.append(value)\n",
    "\n",
    "            no_of_items = len(aggregated_list)\n",
    "\n",
    "            if value > ATH:\n",
    "                ATH = value\n",
    "            elif value < ATL:\n",
    "                ATL = value\n",
    "\n",
    "            median_val = statistics.median(aggregated_list)\n",
    "            avg_val = statistics.mean(aggregated_list)\n",
    "            \n",
    "            #print('At index number: {}'.format(no_of_items))\n",
    "\n",
    "            #print(\"ATH: {}, ATL: {}, Running Median: {}, Running Mean: {}\\n\".format(ATH,ATL,median_val,avg_val))\n",
    "\n",
    "            #date_val = date_values[no_of_items+1]\n",
    "            self.aggregate_df.loc[no_of_items] = [value, ATH ,ATL, median_val, avg_val]\n",
    "            \n",
    "        '''\n",
    "        \n",
    "        '''    \n",
    "        self.aggregate_df['SMA7'] = self.aggregate_df['Close'].rolling(window=7).mean()\n",
    "        self.aggregate_df['SMA30'] = self.aggregate_df['Close'].rolling(window=30).mean()\n",
    "        self.aggregate_df['SMA-MACD'] = self.aggregate_df['SMA7'] - self.aggregate_df['SMA30']\n",
    "        self.aggregate_df['SMA-MACD-ratio'] = self.aggregate_df['SMA7'] / self.aggregate_df['SMA30']\n",
    "        self.aggregate_df['bool_diff_SMA7_SMA30'] = self.aggregate_df['SMA-MACD'].apply(is_ma_pos)\n",
    "        reversed_df = self.raw_df[['date']]\n",
    "        date_list = reversed_df['date'][::-1].tolist()\n",
    "        se = pd.Series(date_list)\n",
    "        self.aggregate_df['date'] = se.values\n",
    "        self.aggregate_df['name'] = self.token_name\n",
    "        self.aggregate_df['close_diff'] = self.aggregate_df['Close'].diff()\n",
    "        self.aggregate_df['bool_close_diff'] = self.aggregate_df['close_diff'].apply(is_ma_pos)\n",
    "        display(self.aggregate_df)\n",
    "        \n",
    "        \n",
    "    def test_sma_values(self):\n",
    "        signal_list = [*range(1, 20, 1)] \n",
    "        ma_list = [*range(21, 50, 1)] \n",
    "        \n",
    "        ATH = algo_close_values[0]\n",
    "        ATL = algo_close_values[0]\n",
    "        MEDIAN = 0\n",
    "        AVERAGE = 0\n",
    "        \n",
    "        aggregated_list = []\n",
    "        self.aggregate_df = pd.DataFrame(columns=['Close','ATH','ATL','Median','Mean'])\n",
    "        \n",
    "        for value in close_values:\n",
    "\n",
    "            aggregated_list.append(value)\n",
    "\n",
    "            no_of_items = len(aggregated_list)\n",
    "\n",
    "            if value > ATH:\n",
    "                ATH = value\n",
    "            elif value < ATL:\n",
    "                ATL = value\n",
    "\n",
    "            median_val = statistics.median(aggregated_list)\n",
    "            avg_val = statistics.mean(aggregated_list)\n",
    "            \n",
    "            #print('At index number: {}'.format(no_of_items))\n",
    "\n",
    "            #print(\"ATH: {}, ATL: {}, Running Median: {}, Running Mean: {}\\n\".format(ATH,ATL,median_val,avg_val))\n",
    "\n",
    "            #date_val = date_values[no_of_items+1]\n",
    "            self.aggregate_df.loc[no_of_items] = [value, ATH ,ATL, median_val, avg_val]\n",
    "            \n",
    "        self.aggregate_df['SMA7'] = self.aggregate_df['Close'].rolling(window=7).mean()\n",
    "        self.aggregate_df['SMA30'] = self.aggregate_df['Close'].rolling(window=30).mean()\n",
    "        self.aggregate_df['SMA-MACD'] = self.aggregate_df['SMA7'] - self.aggregate_df['SMA30']\n",
    "        self.aggregate_df['SMA-MACD-ratio'] = self.aggregate_df['SMA7'] / self.aggregate_df['SMA30']\n",
    "        self.aggregate_df['bool_diff_SMA7_SMA30'] = self.aggregate_df['SMA-MACD'].apply(is_ma_pos)\n",
    "        reversed_df = self.raw_df[['date']]\n",
    "        date_list = reversed_df['date'][::-1].tolist()\n",
    "        se = pd.Series(date_list)\n",
    "        self.aggregate_df['date'] = se.values\n",
    "        self.aggregate_df['name'] = self.token_name\n",
    "        self.aggregate_df['close_diff'] = self.aggregate_df['Close'].diff()\n",
    "        self.aggregate_df['bool_close_diff'] = self.aggregate_df['close_diff'].apply(is_ma_pos)        \n",
    "        \n",
    "        \n",
    "    def visualize_sma(self):\n",
    "        print(\"{} SMA7 and SM30 Chart\".format(self.token_name))\n",
    "        #display(self.aggregate_df.head(5))\n",
    "        fig = px.line(self.aggregate_df, x = 'date', y=['Close','SMA7','SMA30'])\n",
    "        fig.show()\n",
    "        \n",
    "    def calc_ema(self, window):\n",
    "        \n",
    "        col_name = 'EMA'+str(window)\n",
    "        data = self.aggregate_df['Close'].to_numpy()\n",
    "        \n",
    "        alpha = 2 /(window + 1.0)\n",
    "        alpha_rev = 1-alpha\n",
    "\n",
    "        scale = 1/alpha_rev\n",
    "        n = data.shape[0]\n",
    "\n",
    "        r = np.arange(n)\n",
    "        scale_arr = scale**r\n",
    "        offset = data[0]*alpha_rev**(r+1)\n",
    "        pw0 = alpha*alpha_rev**(n-1)\n",
    "\n",
    "        mult = data*pw0*scale_arr\n",
    "        cumsums = mult.cumsum()\n",
    "        out = offset + cumsums*scale_arr[::-1]\n",
    "        \n",
    "        se = pd.Series(out)\n",
    "        self.aggregate_df[col_name] = se.values\n",
    "    \n",
    "    def calc_ema_macd(self):\n",
    "        self.aggregate_df['EMA-MACD'] = self.aggregate_df['EMA12'] - self.aggregate_df['EMA26']\n",
    "        self.aggregate_df['EMA-MACD-ratio'] = self.aggregate_df['EMA12'] / self.aggregate_df['EMA26']\n",
    "        self.aggregate_df['bool_diff_EMA12_EMA26'] = self.aggregate_df['EMA-MACD'].apply(is_ma_pos)\n",
    "        \n",
    "    def visualize_ema(self, EMA_col_name1,EMA_col_name2):\n",
    "        print(\"{} {} and {} Chart\".format(self.token_name, EMA_col_name1,EMA_col_name2))\n",
    "        #display(self.aggregate_df.head(5))\n",
    "        fig = px.line(self.aggregate_df, x = 'date', y=['Close',EMA_col_name1,EMA_col_name2])\n",
    "        fig.show()\n",
    "        \n",
    "    def calc_confusion_matrix(self, sma_or_ema):\n",
    "        \n",
    "        if sma_or_ema == 'sma':\n",
    "            # confusion matrix\n",
    "            matrix = confusion_matrix(self.aggregate_df['bool_close_diff'],self.aggregate_df['bool_diff_SMA7_SMA30'], labels=[1,0])\n",
    "            print('Confusion matrix : \\n',matrix)\n",
    "\n",
    "            # outcome values order in sklearn\n",
    "            tp, fn, fp, tn = confusion_matrix(self.aggregate_df['bool_close_diff'],self.aggregate_df['bool_diff_SMA7_SMA30'],labels=[1,0]).reshape(-1)\n",
    "            print('Outcome values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "            # classification report for precision, recall f1-score and accuracy\n",
    "            matrix = classification_report(self.aggregate_df['bool_close_diff'],self.aggregate_df['bool_diff_SMA7_SMA30'],labels=[1,0])\n",
    "            print('Classification report : \\n',matrix)\n",
    "            print(confusion_matrix)\n",
    "\n",
    "            self.sma_model_accuracy = (tp + tn) / (tp+fn+fp+tn)\n",
    "            print('Model accuracy score: {}'.format(self.sma_model_accuracy))\n",
    "            \n",
    "            return self.sma_model_accuracy\n",
    "        \n",
    "        else:\n",
    "            # confusion matrix\n",
    "            matrix = confusion_matrix(self.aggregate_df['bool_close_diff'],self.aggregate_df['bool_diff_EMA12_EMA26'], labels=[1,0])\n",
    "            print('Confusion matrix : \\n',matrix)\n",
    "\n",
    "            # outcome values order in sklearn\n",
    "            tp, fn, fp, tn = confusion_matrix(self.aggregate_df['bool_close_diff'],self.aggregate_df['bool_diff_EMA12_EMA26'],labels=[1,0]).reshape(-1)\n",
    "            print('Outcome values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "            # classification report for precision, recall f1-score and accuracy\n",
    "            matrix = classification_report(self.aggregate_df['bool_close_diff'],self.aggregate_df['bool_diff_EMA12_EMA26'],labels=[1,0])\n",
    "            print('Classification report : \\n',matrix)\n",
    "            print(confusion_matrix)\n",
    "\n",
    "            self.ema_model_accuracy = (tp + tn) / (tp+fn+fp+tn)\n",
    "            print('Model accuracy score: {}'.format(self.ema_model_accuracy))\n",
    "            \n",
    "            return self.ema_model_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "algo_obj = token('ALGO-USD', 300)\n",
    "algo_obj.calc_sma()\n",
    "algo_obj.visualize_sma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_obj.calc_confusion_matrix('sma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_obj.calc_ema(12)\n",
    "algo_obj.calc_ema(26)\n",
    "algo_obj.calc_ema_macd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_obj.calc_confusion_matrix('ema')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "algo_obj.visualize_ema('EMA12', 'EMA26')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consolidated Token Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_obj = token('ALGO-USD', 300)\n",
    "grt_obj = token('GRT-USD', 300)\n",
    "btc_obj = token('BTC-USD',300)\n",
    "eth_obj = token('ETH-USD',300)\n",
    "aave_obj = token('AAVE-USD',300)\n",
    "atom_obj = token('ATOM-USD',300)\n",
    "bal_obj = token('BAL-USD',300)\n",
    "band_obj = token('BAND-USD',300)\n",
    "eos_obj = token('EOS-USD',300)\n",
    "link_obj = token('LINK-USD',300)\n",
    "ltc_obj = token('LTC-USD',300)\n",
    "nu_obj = token('NU-USD',300)\n",
    "omg_obj = token('OMG-USD',300)\n",
    "uni_obj = token('UNI-USD',300)\n",
    "xlm_obj = token('XLM-USD',300)\n",
    "zrx_obj = token('ZRX-USD',300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_list = [algo_obj, grt_obj, btc_obj, eth_obj, aave_obj, atom_obj, bal_obj, band_obj, eos_obj, link_obj, ltc_obj, nu_obj, omg_obj, uni_obj, xlm_obj, zrx_obj]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and visualize simple moving averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for token in token_list:\n",
    "    token.calc_sma()\n",
    "    token.visualize_sma()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and visualize exponential moving averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for token in token_list:\n",
    "    token.calc_ema(12)\n",
    "    token.calc_ema(26)\n",
    "    token.calc_ema_macd()\n",
    "    token.visualize_ema('EMA12','EMA26')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate confusion matrices and model accuracy scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ema_score_list = []\n",
    "token_name_list = []\n",
    "for token in token_list:\n",
    "    print(\"{} Confusion Matrix\".format(token.token_name))\n",
    "    token_ema = token.calc_confusion_matrix('ema')\n",
    "    ema_score_list.append(token_ema)\n",
    "    \n",
    "    t_name = token.token_name\n",
    "    token_name_list.append(t_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_token_ema_accuracy = list(zip(token_name_list,ema_score_list))\n",
    "print(tuple(complete_token_ema_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(complete_token_ema_accuracy, columns=['Token-Name','Model Decision Accuracy'])\n",
    "df['Model Decision Accuracy'] = df['Model Decision Accuracy'] *100 \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grt_df = grt_obj.return_df()\n",
    "grt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_list = [2,3,4,5,6,7,8,9,10] \n",
    "ma_list = [20,21,22,23,24,25,26,27,28,29,30] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for signal_val in signal_list:\n",
    "    for ma_val in ma_list:\n",
    "        algo_obj.calc_ema(signal_val)\n",
    "        algo_obj.calc_ema(ma_val)\n",
    "        algo_obj.calc_ema_macd()\n",
    "        token_ema = algo_obj.calc_confusion_matrix('ema')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ema_array(data,window):\n",
    "    alpha = 2 /(window + 1.0)\n",
    "    alpha_rev = 1-alpha\n",
    "\n",
    "    scale = 1/alpha_rev\n",
    "    n = data.shape[0]\n",
    "\n",
    "    r = np.arange(n)\n",
    "    scale_arr = scale**r\n",
    "    offset = data[0]*alpha_rev**(r+1)\n",
    "    pw0 = alpha*alpha_rev**(n-1)\n",
    "\n",
    "    mult = data*pw0*scale_arr\n",
    "    cumsums = mult.cumsum()\n",
    "    out = offset + cumsums*scale_arr[::-1]\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class token:\n",
    "    \n",
    "    def __init__(self, name, num_of_days):\n",
    "        \n",
    "        print(\"Creating {} object ...\".format(name))\n",
    "        self.REST_API = 'https://api.pro.coinbase.com'\n",
    "        self.PRODUCTS = REST_API+'/products'\n",
    "        \n",
    "        self.token_name = name\n",
    "        self.token_url = '/'+name+'/candles'\n",
    "        \n",
    "        self.start_date = (datetime.today() - timedelta(days=300)).isoformat()\n",
    "        self.end_date = datetime.now().isoformat()\n",
    "        \n",
    "        # Please refer to the coinbase documentation on the expected parameters\n",
    "        self.params = {'start':self.start_date, 'end':self.end_date, 'granularity':'86400'}\n",
    "        self.response = connect(PRODUCTS+ self.token_url, param = params)\n",
    "        \n",
    "        self.response_text = self.response.text\n",
    "        \n",
    "        self.raw_df = pd.read_json(self.response_text)\n",
    "        \n",
    "        self.raw_df.columns = ['time','low','high','open','close','volume']\n",
    "        self.raw_df['date'] = pd.to_datetime(self.raw_df['time'], unit='s')\n",
    "        self.raw_df['year'] = pd.DatetimeIndex(self.raw_df['date']).year\n",
    "        self.raw_df['month'] = pd.DatetimeIndex(self.raw_df['date']).month\n",
    "        self.raw_df['day'] = pd.DatetimeIndex(self.raw_df['date']).day\n",
    "        self.raw_df['hour'] = pd.DatetimeIndex(self.raw_df['date']).hour.astype(str)\n",
    "        self.raw_df['name'] = self.token_name\n",
    "        #self.raw_df.set_index('date', inplace=True)\n",
    "        \n",
    "        self.sma_signal = 7\n",
    "        self.sma_ma = 25\n",
    "        self.ema_signal = 12\n",
    "        self.ema_ma = 26\n",
    "        self.sma_model_accuracy = 0\n",
    "        self.ema_model_accuracy = 0\n",
    "        \n",
    "    def return_df(self):\n",
    "        \n",
    "        return self.aggregate_df\n",
    "    \n",
    "\n",
    "    def calc_sma(self):\n",
    "        \n",
    "        close_values = self.raw_df['close'][::-1].tolist()\n",
    "    \n",
    "        \n",
    "        INVESTMENT = 100 # initial investment\n",
    "        NO_OF_RECORDS = 0 # number of transactions\n",
    "        ATH = algo_close_values[0]\n",
    "        ATL = algo_close_values[0]\n",
    "        MEDIAN = 0\n",
    "        AVERAGE = 0\n",
    "        \n",
    "        aggregated_list = []\n",
    "        self.aggregate_df = pd.DataFrame(columns=['Close','ATH','ATL','Median','Mean'])\n",
    "        \n",
    "        for value in close_values:\n",
    "\n",
    "            aggregated_list.append(value)\n",
    "\n",
    "            no_of_items = len(aggregated_list)\n",
    "\n",
    "            if value > ATH:\n",
    "                ATH = value\n",
    "            elif value < ATL:\n",
    "                ATL = value\n",
    "\n",
    "            median_val = statistics.median(aggregated_list)\n",
    "            avg_val = statistics.mean(aggregated_list)\n",
    "            \n",
    "            #print('At index number: {}'.format(no_of_items))\n",
    "\n",
    "            #print(\"ATH: {}, ATL: {}, Running Median: {}, Running Mean: {}\\n\".format(ATH,ATL,median_val,avg_val))\n",
    "\n",
    "            #date_val = date_values[no_of_items+1]\n",
    "            self.aggregate_df.loc[no_of_items] = [value, ATH ,ATL, median_val, avg_val]\n",
    "            \n",
    "        '''\n",
    "        \n",
    "        '''    \n",
    "        self.aggregate_df['SMA7'] = self.aggregate_df['Close'].rolling(window=7).mean()\n",
    "        self.aggregate_df['SMA30'] = self.aggregate_df['Close'].rolling(window=30).mean()\n",
    "        self.aggregate_df['SMA-MACD'] = self.aggregate_df['SMA7'] - self.aggregate_df['SMA30']\n",
    "        self.aggregate_df['SMA-MACD-ratio'] = self.aggregate_df['SMA7'] / self.aggregate_df['SMA30']\n",
    "        self.aggregate_df['bool_diff_SMA7_SMA30'] = self.aggregate_df['SMA-MACD'].apply(is_ma_pos)\n",
    "        reversed_df = self.raw_df[['date']]\n",
    "        date_list = reversed_df['date'][::-1].tolist()\n",
    "        se = pd.Series(date_list)\n",
    "        self.aggregate_df['date'] = se.values\n",
    "        self.aggregate_df['name'] = self.token_name\n",
    "        self.aggregate_df['close_diff'] = self.aggregate_df['Close'].diff()\n",
    "        self.aggregate_df['bool_close_diff'] = self.aggregate_df['close_diff'].apply(is_ma_pos)\n",
    "        display(self.aggregate_df)\n",
    "        \n",
    "        \n",
    "    def test_sma_values(self):\n",
    "        signal_list = [*range(1, 20, 1)] \n",
    "        ma_list = [*range(21, 50, 1)] \n",
    "        \n",
    "        ATH = algo_close_values[0]\n",
    "        ATL = algo_close_values[0]\n",
    "        MEDIAN = 0\n",
    "        AVERAGE = 0\n",
    "        \n",
    "        aggregated_list = []\n",
    "        self.aggregate_df = pd.DataFrame(columns=['Close','ATH','ATL','Median','Mean'])\n",
    "        \n",
    "        for value in close_values:\n",
    "\n",
    "            aggregated_list.append(value)\n",
    "\n",
    "            no_of_items = len(aggregated_list)\n",
    "\n",
    "            if value > ATH:\n",
    "                ATH = value\n",
    "            elif value < ATL:\n",
    "                ATL = value\n",
    "\n",
    "            median_val = statistics.median(aggregated_list)\n",
    "            avg_val = statistics.mean(aggregated_list)\n",
    "            \n",
    "            #print('At index number: {}'.format(no_of_items))\n",
    "\n",
    "            #print(\"ATH: {}, ATL: {}, Running Median: {}, Running Mean: {}\\n\".format(ATH,ATL,median_val,avg_val))\n",
    "\n",
    "            #date_val = date_values[no_of_items+1]\n",
    "            self.aggregate_df.loc[no_of_items] = [value, ATH ,ATL, median_val, avg_val]\n",
    "            \n",
    "        self.aggregate_df['SMA7'] = self.aggregate_df['Close'].rolling(window=7).mean()\n",
    "        self.aggregate_df['SMA30'] = self.aggregate_df['Close'].rolling(window=30).mean()\n",
    "        self.aggregate_df['SMA-MACD'] = self.aggregate_df['SMA7'] - self.aggregate_df['SMA30']\n",
    "        self.aggregate_df['SMA-MACD-ratio'] = self.aggregate_df['SMA7'] / self.aggregate_df['SMA30']\n",
    "        self.aggregate_df['bool_diff_SMA7_SMA30'] = self.aggregate_df['SMA-MACD'].apply(is_ma_pos)\n",
    "        reversed_df = self.raw_df[['date']]\n",
    "        date_list = reversed_df['date'][::-1].tolist()\n",
    "        se = pd.Series(date_list)\n",
    "        self.aggregate_df['date'] = se.values\n",
    "        self.aggregate_df['name'] = self.token_name\n",
    "        self.aggregate_df['close_diff'] = self.aggregate_df['Close'].diff()\n",
    "        self.aggregate_df['bool_close_diff'] = self.aggregate_df['close_diff'].apply(is_ma_pos)        \n",
    "        \n",
    "        \n",
    "    def visualize_sma(self):\n",
    "        print(\"{} SMA7 and SM30 Chart\".format(self.token_name))\n",
    "        #display(self.aggregate_df.head(5))\n",
    "        fig = px.line(self.aggregate_df, x = 'date', y=['Close','SMA7','SMA30'])\n",
    "        fig.show()\n",
    "        \n",
    "\n",
    "        \n",
    "    def calc_ema(self, window1, window2):\n",
    "        \n",
    "        self.col1_name = 'EMA'+str(window1)\n",
    "        self.col2_name = 'EMA'+str(window2)\n",
    "        data = self.aggregate_df['Close'].to_numpy()\n",
    "        \n",
    "        alpha1 = 2 /(window1 + 1.0)\n",
    "        alpha_rev1 = 1-alpha1\n",
    "\n",
    "        scale1 = 1/alpha_rev1\n",
    "        n1 = data.shape[0]\n",
    "\n",
    "        r1 = np.arange(n1)\n",
    "        scale_arr1 = scale1**r1\n",
    "        offset1 = data[0]*alpha_rev1**(r1+1)\n",
    "        pw01 = alpha1*alpha_rev1**(n1-1)\n",
    "\n",
    "        mult1 = data*pw01*scale_arr1\n",
    "        cumsums1 = mult1.cumsum()\n",
    "        out1 = offset1 + cumsums1*scale_arr1[::-1]\n",
    "\n",
    "        #\n",
    "        alpha2 = 2 /(window2 + 1.0)\n",
    "        alpha_rev2 = 1-alpha2\n",
    "\n",
    "        scale2 = 1/alpha_rev2\n",
    "        n2 = data.shape[0]\n",
    "\n",
    "        r2 = np.arange(n2)\n",
    "        scale_arr2 = scale2**r2\n",
    "        offset2 = data[0]*alpha_rev2**(r2+1)\n",
    "        pw02 = alpha2*alpha_rev2**(n2-1)\n",
    "\n",
    "        mult2 = data*pw02*scale_arr2\n",
    "        cumsums2 = mult2.cumsum()\n",
    "        out2 = offset2 + cumsums2*scale_arr2[::-1]\n",
    "\n",
    "\n",
    "        \n",
    "        se1 = pd.Series(out1)\n",
    "        se2 = pd.Series(out2)\n",
    "        self.aggregate_df[self.col1_name] = se1.values\n",
    "        self.aggregate_df[self.col2_name] = se2.values\n",
    "        \n",
    "    def calc_ema_macd(self):\n",
    "        self.aggregate_df['EMA-MACD'] = self.aggregate_df[self.col1_name] - self.aggregate_df[self.col2_name]\n",
    "        self.aggregate_df['EMA-MACD-ratio'] = self.aggregate_df[self.col1_name] / self.aggregate_df[self.col2_name]\n",
    "        self.aggregate_df['bool_diff_signal_ma'] = self.aggregate_df['EMA-MACD'].apply(is_ma_pos)\n",
    "        \n",
    "    def visualize_ema(self, EMA_col_name1,EMA_col_name2):\n",
    "        print(\"{} {} and {} Chart\".format(self.token_name, EMA_col_name1,EMA_col_name2))\n",
    "        #display(self.aggregate_df.head(5))\n",
    "        fig = px.line(self.aggregate_df, x = 'date', y=['Close',EMA_col_name1,EMA_col_name2])\n",
    "        fig.show()\n",
    "        \n",
    "    def calc_confusion_matrix(self, sma_or_ema):\n",
    "        \n",
    "        if sma_or_ema == 'sma':\n",
    "            # confusion matrix\n",
    "            matrix = confusion_matrix(self.aggregate_df['bool_close_diff'],self.aggregate_df['bool_diff_SMA7_SMA30'], labels=[1,0])\n",
    "            print('Confusion matrix : \\n',matrix)\n",
    "\n",
    "            # outcome values order in sklearn\n",
    "            tp, fn, fp, tn = confusion_matrix(self.aggregate_df['bool_close_diff'],self.aggregate_df['bool_diff_SMA7_SMA30'],labels=[1,0]).reshape(-1)\n",
    "            print('Outcome values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "            # classification report for precision, recall f1-score and accuracy\n",
    "            matrix = classification_report(self.aggregate_df['bool_close_diff'],self.aggregate_df['bool_diff_SMA7_SMA30'],labels=[1,0])\n",
    "            print('Classification report : \\n',matrix)\n",
    "            print(confusion_matrix)\n",
    "\n",
    "            self.sma_model_accuracy = (tp + tn) / (tp+fn+fp+tn)\n",
    "            print('Model accuracy score: {}'.format(self.sma_model_accuracy))\n",
    "            \n",
    "            return self.sma_model_accuracy\n",
    "        \n",
    "        else:\n",
    "            # confusion matrix\n",
    "            matrix = confusion_matrix(self.aggregate_df['bool_close_diff'],self.aggregate_df['bool_diff_signal_ma'], labels=[1,0])\n",
    "            print('Confusion matrix : \\n',matrix)\n",
    "\n",
    "            # outcome values order in sklearn\n",
    "            tp, fn, fp, tn = confusion_matrix(self.aggregate_df['bool_close_diff'],self.aggregate_df['bool_diff_signal_ma'],labels=[1,0]).reshape(-1)\n",
    "            print('Outcome values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "            # classification report for precision, recall f1-score and accuracy\n",
    "            matrix = classification_report(self.aggregate_df['bool_close_diff'],self.aggregate_df['bool_diff_signal_ma'],labels=[1,0])\n",
    "            print('Classification report : \\n',matrix)\n",
    "            print(confusion_matrix)\n",
    "\n",
    "            self.ema_model_accuracy = (tp + tn) / (tp+fn+fp+tn)\n",
    "            print('Model accuracy score: {}'.format(self.ema_model_accuracy))\n",
    "            \n",
    "            return self.ema_model_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_list = [2,3,4,5,6,7,8,9,10] \n",
    "ma_list = [20,21,22,23,24,25,26,27,28,29,30] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "algo_obj = token('ALGO-USD', 300)\n",
    "for signal_val in signal_list:\n",
    "    for ma_val in ma_list:\n",
    "        algo_obj.calc_sma()\n",
    "        algo_obj.calc_ema(signal_val, ma_val)\n",
    "        algo_obj.calc_ema_macd()\n",
    "        algo_obj.calc_confusion_matrix('ema')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
